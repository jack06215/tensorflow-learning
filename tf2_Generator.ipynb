{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://biswajitsahoo1111.github.io/post/efficiently-reading-multiple-files-in-tensorflow-2/\n",
    "\n",
    "https://biswajitsahoo1111.github.io/post/reading-multiple-files-in-tensorflow-2-using-sequence/\n",
    "\n",
    "https://biswajitsahoo1111.github.io/post/doing-linear-algebra-using-tensorflow-2/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version:  2.5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow Version: \", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randint(100, 150, size=(10, 2, 2))\n",
    "labels = np.random.permutation(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_generator(data, labels, batch_size=2):\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i * batch_size >= len(labels):\n",
    "            i = 0\n",
    "            idx = np.random.permutation(len(labels))\n",
    "            data, labels = data[idx], labels[idx]\n",
    "            continue\n",
    "        else:\n",
    "            X = data[i * batch_size:(i + 1) * batch_size, :]\n",
    "            y = labels[i * batch_size:(i + 1) * batch_size]\n",
    "            i += 1\n",
    "            yield X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n"
     ]
    }
   ],
   "source": [
    "get_data = my_generator(data, labels)\n",
    "for i in range(10):\n",
    "    X, y = next(get_data)\n",
    "    print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above generator code, we manually shuffled the data between epochs. But in TensorFlow we can use Sequence class to do this for us automatically. The added advantage of using this class is that we can use multiprocessing capabilities. So the new generator code becomes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tf_my_generator(Sequence):\n",
    "    def __init__(self, data, labels, batch_size=2):\n",
    "        self.x, self.y = data, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(self.x.shape[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return tf.math.floor(self.x.shape[0] / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inds = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = self.x[inds]\n",
    "        batch_y = self.y[inds]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n",
      "(2, 2, 2) (2,)\n"
     ]
    }
   ],
   "source": [
    "get_new_data = tf_my_generator(data, labels)\n",
    "for i in range(10):\n",
    "    if i == 5:\n",
    "        get_new_data.on_epoch_end()\n",
    "        i = 0\n",
    "    elif i > 5:\n",
    "        i = i-5\n",
    "    X, y = get_new_data.__getitem__(i)\n",
    "    print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the generators work fine. Now we will use it to implement a CNN model on MNIST data. Note that this example is bit stretched and strange. We don't need generators to implement small data sets like MNIST. Whole of MNIST can be loaded into RAM. By this example the aim is just to show a different way of implementing it using generators. Of course the codes can be modified to handle cases where we indeed need generators to do analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data,\n",
    "                             test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "train_data = train_data.reshape(60000, 28, 28, 1)/255.\n",
    "id = np.random.permutation(len(train_labels))\n",
    "training_data, training_labels = train_data[id[0:48000]\n",
    "                                            ], train_labels[id[0:48000]]\n",
    "val_data, val_labels = train_data[id[48000:60000]\n",
    "                                  ], train_labels[id[48000:60000]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPool2D(2),\n",
    "    Conv2D(64, 5, activation='relu'),\n",
    "    MaxPool2D(2),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras requires the generator to run indefinitely\n",
    "class data_gen(Sequence):\n",
    "    def __init__(self, data, labels, batch_size=128):\n",
    "        self.x, self.y = data, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(self.x.shape[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(tf.math.ceil(self.x.shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inds = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = self.x[inds]\n",
    "        batch_y = self.y[inds]\n",
    "        return batch_x, tf.keras.utils.to_categorical(batch_y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = data_gen(train_data, train_labels, batch_size=128)\n",
    "val_gen = data_gen(val_data, val_labels, batch_size=128)\n",
    "batch_size = 128\n",
    "steps_per_epoch = np.floor(len(train_labels)/batch_size)\n",
    "val_steps = np.floor(len(val_labels)/batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "468/468 [==============================] - 28s 57ms/step - loss: 0.2446 - accuracy: 0.9287 - val_loss: 0.0863 - val_accuracy: 0.9762\n",
      "Epoch 2/10\n",
      "468/468 [==============================] - 25s 54ms/step - loss: 0.0683 - accuracy: 0.9793 - val_loss: 0.0542 - val_accuracy: 0.9835\n",
      "Epoch 3/10\n",
      "468/468 [==============================] - 26s 55ms/step - loss: 0.0478 - accuracy: 0.9853 - val_loss: 0.0426 - val_accuracy: 0.9871\n",
      "Epoch 4/10\n",
      "468/468 [==============================] - 27s 57ms/step - loss: 0.0370 - accuracy: 0.9884 - val_loss: 0.0324 - val_accuracy: 0.9896\n",
      "Epoch 5/10\n",
      "468/468 [==============================] - 28s 61ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.0296 - val_accuracy: 0.9903\n",
      "Epoch 6/10\n",
      "468/468 [==============================] - 33s 70ms/step - loss: 0.0238 - accuracy: 0.9925 - val_loss: 0.0206 - val_accuracy: 0.9935\n",
      "Epoch 7/10\n",
      "468/468 [==============================] - 33s 70ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.0196 - val_accuracy: 0.9941\n",
      "Epoch 8/10\n",
      "468/468 [==============================] - 31s 67ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.0126 - val_accuracy: 0.9963\n",
      "Epoch 9/10\n",
      "468/468 [==============================] - 31s 66ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.0116 - val_accuracy: 0.9958\n",
      "Epoch 10/10\n",
      "468/468 [==============================] - 31s 66ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.0070 - val_accuracy: 0.9982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bed8a2ab08>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen, steps_per_epoch=steps_per_epoch, epochs=10,\n",
    "          validation_data=val_gen, validation_steps=val_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.0329 - accuracy: 0.9898\n",
      "Test Loss: 0.03287464752793312\n",
      "Test Accuracy: 0.989799976348877\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data.reshape(\n",
    "    10000, 28, 28, 1)/255., tf.keras.utils.to_categorical(test_labels), verbose=2)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46c36fa438a0e5217cf9152cd05c2dbbe7da14e3af0a2f78612f95babe496324"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
